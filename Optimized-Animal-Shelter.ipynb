{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d1354-e24d-4847-9806-de0660959afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(\"Train shape:\", train.shape, \" Test shape:\", test.shape)\n",
    "print(\"Train columns:\", train.columns.tolist())\n",
    "print(\"Test columns:\", test.columns.tolist())\n",
    "\n",
    "# Drop columns not available in test\n",
    "train = train.drop(['Name', 'Outcome Time', 'Outcome Subtype'] if 'Outcome Subtype' in train.columns else ['Name','Outcome Time'], axis=1)\n",
    "# drop 'Date of Birth' since we will use age instead\n",
    "train = train.drop('Date of Birth', axis=1)\n",
    "test = test.drop('Date of Birth', axis=1)\n",
    "# Confirm columns after drop\n",
    "print(\"Train columns after drop:\", train.columns.tolist())\n",
    "print(\"Test columns after drop:\", test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a302eb-573e-45d0-b71d-5dcdc8c58460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix missing values\n",
    "train['Sex upon Intake'] = train['Sex upon Intake'].fillna('Unknown')\n",
    "missing_age_count = train['Age upon Intake'].isna().sum()\n",
    "if missing_age_count > 0:\n",
    "    # Drop the one record with missing age\n",
    "    train = train[~train['Age upon Intake'].isna()]\n",
    "print(\"Remaining missing values in train:\", train.isnull().sum().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3efe2-83ac-44c0-9ca5-a66c76d452db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def age_to_days(age_str):\n",
    "    if pd.isna(age_str):\n",
    "        return None\n",
    "    age_str = age_str.lower().strip()\n",
    "    if age_str == 'unknown':\n",
    "        return None\n",
    "    # Split into number and unit\n",
    "    parts = age_str.split()\n",
    "    if len(parts) != 2:\n",
    "        return None\n",
    "    num, unit = parts\n",
    "    try:\n",
    "        num = int(num)\n",
    "    except:\n",
    "        num = 0\n",
    "    unit = unit.rstrip('s')\n",
    "    # Convert to days\n",
    "    if unit == 'day':\n",
    "        return num\n",
    "    elif unit == 'week':\n",
    "        return num * 7\n",
    "    elif unit == 'month':\n",
    "        return num * 30\n",
    "    elif unit == 'year':\n",
    "        return num * 365\n",
    "    return None\n",
    "\n",
    "# convert age upon intake\n",
    "train['AgeDays'] = train['Age upon Intake'].apply(age_to_days)\n",
    "test['AgeDays'] = test['Age upon Intake'].apply(age_to_days)\n",
    "print(train[['Age upon Intake','AgeDays']].head(3))\n",
    "# Drop the original age text column\n",
    "train = train.drop('Age upon Intake', axis=1)\n",
    "test = test.drop('Age upon Intake', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5eb2b-fd82-45a2-b678-5dd1794d403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Intake Time to datetime and extract components\n",
    "train['IntakeDatetime'] = pd.to_datetime(train['Intake Time'])\n",
    "test['IntakeDatetime'] = pd.to_datetime(test['Intake Time'])\n",
    "\n",
    "train['IntakeYear'] = train['IntakeDatetime'].dt.year\n",
    "train['IntakeMonth'] = train['IntakeDatetime'].dt.month\n",
    "train['IntakeHour'] = train['IntakeDatetime'].dt.hour\n",
    "train['IntakeDow'] = train['IntakeDatetime'].dt.dayofweek\n",
    "train['IsWeekend'] = train['IntakeDow'].isin([5,6]).astype(int)\n",
    "\n",
    "test['IntakeYear'] = test['IntakeDatetime'].dt.year\n",
    "test['IntakeMonth'] = test['IntakeDatetime'].dt.month\n",
    "test['IntakeHour'] = test['IntakeDatetime'].dt.hour\n",
    "test['IntakeDow'] = test['IntakeDatetime'].dt.dayofweek\n",
    "test['IsWeekend'] = test['IntakeDow'].isin([5,6]).astype(int)\n",
    "\n",
    "\n",
    "train = train.drop(['Intake Time','IntakeDatetime'], axis=1)\n",
    "test = test.drop(['Intake Time','IntakeDatetime'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a24ffa-b331-416a-9cf4-22cb00d14af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Breed Parsing\n",
    "def process_breed(breed):\n",
    "    breed = breed.strip()\n",
    "    breed = breed.replace(\"Black/Tan Hound\", \"Black Tan Hound\")\n",
    "    \n",
    "    breed = re.sub(r'\\s+Mix$', '', breed, flags=re.IGNORECASE)\n",
    "    breed = breed.strip()\n",
    "    \n",
    "    if \"/\" in breed:\n",
    "        parts = breed.split(\"/\")\n",
    "    else:\n",
    "        parts = [breed]\n",
    "    if len(parts) > 2:\n",
    "        parts = [\"/\".join(parts[:-1]), parts[-1]]\n",
    "    primary = parts[0].strip()\n",
    "    secondary = parts[1].strip() if len(parts) > 1 else None\n",
    "    \n",
    "    is_mix = 1 if (\"mix\" in breed.lower() or len(parts) > 1) else 0\n",
    "    \n",
    "    if is_mix and secondary is None:\n",
    "        secondary = \"Unknown\"\n",
    "    if secondary is None:\n",
    "        secondary = \"None\"\n",
    "    return primary, secondary, is_mix\n",
    "\n",
    "\n",
    "breed_info_train = train['Breed'].apply(process_breed)\n",
    "train['Breed_Primary'] = breed_info_train.apply(lambda x: x[0])\n",
    "train['Breed_Secondary'] = breed_info_train.apply(lambda x: x[1])\n",
    "train['IsMix'] = breed_info_train.apply(lambda x: x[2])\n",
    "\n",
    "breed_info_test = test['Breed'].apply(process_breed)\n",
    "test['Breed_Primary'] = breed_info_test.apply(lambda x: x[0])\n",
    "test['Breed_Secondary'] = breed_info_test.apply(lambda x: x[1])\n",
    "test['IsMix'] = breed_info_test.apply(lambda x: x[2])\n",
    "\n",
    "# Sample output of head\n",
    "print(train[['Breed','Breed_Primary','Breed_Secondary','IsMix']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96da6a5-fbf5-4478-b44b-fd736a57bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rare primary breeds\n",
    "primary_counts = train['Breed_Primary'].value_counts()\n",
    "common_primaries = set(primary_counts[primary_counts >= 100].index)\n",
    "train['Breed_Primary_Cat'] = train['Breed_Primary'].apply(lambda x: x if x in common_primaries else \"Other\")\n",
    "test['Breed_Primary_Cat'] = test['Breed_Primary'].apply(lambda x: x if x in common_primaries else \"Other\")\n",
    "\n",
    "# Group rare secondary breeds\n",
    "secondary_counts = train['Breed_Secondary'].value_counts()\n",
    "common_secondaries = set(secondary_counts[secondary_counts >= 100].index)\n",
    "train['Breed_Secondary_Cat'] = train['Breed_Secondary'].apply(lambda x: x if x in common_secondaries else \"Other\")\n",
    "test['Breed_Secondary_Cat'] = test['Breed_Secondary'].apply(lambda x: x if x in common_secondaries else \"Other\")\n",
    "\n",
    "print(\"Unique primary breed categories (grouped):\", train['Breed_Primary_Cat'].nunique())\n",
    "print(\"Unique secondary breed categories (grouped):\", train['Breed_Secondary_Cat'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9df0f-1d1e-4a93-8c3f-10d17e83204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got patterns through printing\n",
    "patterns = [\"tabby\",\"brindle\",\"tortie\",\"torbie\",\"calico\",\"tricolor\",\"merle\",\"point\",\"tick\"]\n",
    "\n",
    "def process_color(color):\n",
    "    color = color.strip().lower()\n",
    "    # Identify pattern flags\n",
    "    pattern_flags = {p: (1 if p in color else 0) for p in patterns}\n",
    "    # Split into primary/secondary parts\n",
    "    parts = [part.strip() for part in color.split('/')]\n",
    "    if len(parts) > 2:\n",
    "        parts = [parts[0], parts[1]]\n",
    "    primary_part = parts[0]\n",
    "    secondary_part = parts[1] if len(parts) > 1 else None\n",
    "    def remove_pattern_words(col):\n",
    "        if col is None: \n",
    "            return None\n",
    "        for pat in [\"tabby\",\"brindle\",\"merle\",\"point\",\"tick\"]:\n",
    "            if col.endswith(\" \" + pat):\n",
    "                col = col[: -len(pat) - 1]\n",
    "        return col.strip()\n",
    "    base_primary = remove_pattern_words(primary_part).title() if primary_part else \"Unknown\"\n",
    "    base_secondary = remove_pattern_words(secondary_part).title() if secondary_part else None\n",
    "    if base_secondary is None:\n",
    "        base_secondary = \"None\"\n",
    "    is_multi = 1 if len(parts) > 1 else 0\n",
    "    if len(parts) == 1 and any(p in color for p in [\"calico\",\"tricolor\",\"tortie\",\"torbie\"]):\n",
    "        is_multi = 1\n",
    "    return base_primary, base_secondary, is_multi, pattern_flags\n",
    "\n",
    "# Apply color parsing\n",
    "color_info_train = train['Color'].apply(process_color)\n",
    "train['Color_Primary'] = color_info_train.apply(lambda x: x[0])\n",
    "train['Color_Secondary'] = color_info_train.apply(lambda x: x[1])\n",
    "train['IsMultiColor'] = color_info_train.apply(lambda x: x[2])\n",
    "for p in patterns:\n",
    "    train['Pattern_'+p.capitalize()] = color_info_train.apply(lambda x: x[3][p])\n",
    "\n",
    "color_info_test = test['Color'].apply(process_color)\n",
    "test['Color_Primary'] = color_info_test.apply(lambda x: x[0])\n",
    "test['Color_Secondary'] = color_info_test.apply(lambda x: x[1])\n",
    "test['IsMultiColor'] = color_info_test.apply(lambda x: x[2])\n",
    "for p in patterns:\n",
    "    test['Pattern_'+p.capitalize()] = color_info_test.apply(lambda x: x[3][p])\n",
    "\n",
    "#print some parsed features\n",
    "print(train[['Color','Color_Primary','Color_Secondary','IsMultiColor','Pattern_Tabby','Pattern_Calico']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da00c7-edc1-4d81-8af5-a728feb9279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(location):\n",
    "    loc = location.strip()\n",
    "    if \"Outside\" in loc:\n",
    "        return \"Outside\"\n",
    "    if \" in \" in loc:\n",
    "        # Use the part after the last \" in \" and before \" (TX\"\n",
    "        city = loc[loc.rfind(\" in \") + 4 : loc.rfind(\" (\")]\n",
    "        return city\n",
    "    # If no \" in \", just remove the trailing state code\n",
    "    if loc.endswith(\"(TX)\"):\n",
    "        return loc[:loc.rfind(\" (\")]\n",
    "    return loc\n",
    "\n",
    "# Extract the found city for both train and test sets\n",
    "train['Found_City'] = train['Found Location'].apply(extract_city)\n",
    "test['Found_City'] = test['Found Location'].apply(extract_city)\n",
    "\n",
    "# Set a minimum threshold for the frequency of a city\n",
    "min_threshold = 100\n",
    "city_counts = train['Found_City'].value_counts()\n",
    "cities_to_keep = city_counts[city_counts >= min_threshold].index.tolist()\n",
    "\n",
    "def group_city(city, cities_to_keep=cities_to_keep):\n",
    "    # If the city appears less than the threshold, group it as \"Other Found City\"\n",
    "    return city if city in cities_to_keep else \"Other Found City\"\n",
    "\n",
    "# Create a new grouped column for the found city\n",
    "train['Found_City_Grouped'] = train['Found_City'].apply(group_city)\n",
    "test['Found_City_Grouped'] = test['Found_City'].apply(group_city)\n",
    "\n",
    "# print the counts to check grouping\n",
    "print(train['Found_City_Grouped'].value_counts())\n",
    "\n",
    "# Retain the Found_In_Austin indicator if needed\n",
    "train['Found_In_Austin'] = (train['Found_City'] == 'Austin').astype(int)\n",
    "test['Found_In_Austin'] = (test['Found_City'] == 'Austin').astype(int)\n",
    "\n",
    "train = train.drop(['Found_City'], axis=1)\n",
    "test = test.drop(['Found_City'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d19c1d-57a2-4686-8b14-dbd3b7c890d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Sex upon Intake into Gender and Fixed(spayed/neutered) status\n",
    "def split_sex(sex_str):\n",
    "    s = sex_str.lower()\n",
    "    if s.startswith(\"neutered\") or s.startswith(\"spayed\"):\n",
    "        fixed = \"Yes\"\n",
    "    elif s.startswith(\"intact\"):\n",
    "        fixed = \"No\"\n",
    "    else:\n",
    "        fixed = \"Unknown\"\n",
    "    if \"female\" in s:\n",
    "        gender = \"Female\"\n",
    "    elif \"male\" in s:\n",
    "        gender = \"Male\"\n",
    "    else:\n",
    "        gender = \"Unknown\"\n",
    "    return gender, fixed\n",
    "\n",
    "train[['Gender','Fixed']] = pd.DataFrame(train['Sex upon Intake'].apply(split_sex).tolist(), index=train.index)\n",
    "test[['Gender','Fixed']] = pd.DataFrame(test['Sex upon Intake'].apply(split_sex).tolist(), index=test.index)\n",
    "# Drop original Sex column\n",
    "train = train.drop('Sex upon Intake', axis=1)\n",
    "test = test.drop('Sex upon Intake', axis=1)\n",
    "print(train[['Gender','Fixed']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb41304-8ef0-491b-8b48-29a6d1a09782",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Outcome Type']\n",
    "\n",
    "# Drop all raw and unnecessary text/ID columns from both train and test\n",
    "columns_to_drop = [\n",
    "    'Outcome Type',     # target variable\n",
    "    'Breed',            # raw text breed\n",
    "    'Color',            # raw text color\n",
    "    'Found Location',   # raw text found location\n",
    "    'Id',               \n",
    "    'Breed_Primary',    \n",
    "    'Breed_Secondary',\n",
    "    'Color_Primary',\n",
    "    'Color_Secondary',\n",
    "]\n",
    "\n",
    "train_features = train.drop(columns=[col for col in columns_to_drop if col in train.columns], axis=1)\n",
    "test_features = test.drop(columns=[col for col in columns_to_drop if col in test.columns and col != 'Outcome Type'], axis=1)\n",
    "\n",
    "# Align columns, handling potential diffs\n",
    "train_cols = set(train_features.columns)\n",
    "test_cols = set(test_features.columns)\n",
    "\n",
    "missing_in_test = list(train_cols - test_cols)\n",
    "for c in missing_in_test:\n",
    "    if c != 'Outcome Type': \n",
    "        test_features[c] = 0 \n",
    "\n",
    "missing_in_train = list(test_cols - train_cols)\n",
    "for c in missing_in_train:\n",
    "    train_features[c] = 0 # Or appropriate default value\n",
    "\n",
    "# Ensure column order is the same\n",
    "test_features = test_features[train_features.columns]\n",
    "\n",
    "\n",
    "# Identify remaining categorical columns for one-hot encoding\n",
    "categorical_cols = train_features.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# Ensure list only contains columns present in the dataframe\n",
    "categorical_cols = [col for col in categorical_cols if col in train_features.columns]\n",
    "\n",
    "print(\"Categorical columns for one-hot encoding:\", categorical_cols)\n",
    "\n",
    "\n",
    "# One-hot encode categorical features\n",
    "for col in categorical_cols:\n",
    "    combined_cats = pd.concat([train_features[col], test_features[col]], axis=0).unique()\n",
    "    train_features[col] = pd.Categorical(train_features[col], categories=combined_cats)\n",
    "    test_features[col] = pd.Categorical(test_features[col], categories=combined_cats)\n",
    "\n",
    "full_data = pd.concat([train_features, test_features], axis=0, ignore_index=True)\n",
    "full_dummies = pd.get_dummies(full_data, columns=categorical_cols, drop_first=False, dummy_na=False) # Set dummy_na=True if NaNs should have their own column\n",
    "print(\"Total features after one-hot:\", full_dummies.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258b584-f600-4e86-8fd7-55cc86a5f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "full_dummies_imputed = imputer.fit_transform(full_dummies)\n",
    "full_dummies = pd.DataFrame(full_dummies_imputed, columns=full_dummies.columns)\n",
    "\n",
    "\n",
    "# Split encoded data back into train/test\n",
    "X_train_enc = full_dummies.iloc[:len(train_features), :].copy()\n",
    "X_test_enc = full_dummies.iloc[len(train_features):, :].copy()\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_enc)\n",
    "X_test_scaled = scaler.transform(X_test_enc)\n",
    "\n",
    "\n",
    "# Encode target labels to numeric indices\n",
    "classes = sorted(y.unique())\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "y_num = y.map(class_to_idx)\n",
    "print(\"Target classes:\", classes)\n",
    "print(\"Encoded target mapping:\", class_to_idx)\n",
    "\n",
    "\n",
    "# Compute class weights\n",
    "class_counts = y_num.value_counts().to_dict()\n",
    "num_classes = len(classes)\n",
    "total_samples = len(y_num)\n",
    "# Calculate weights using: n_samples / (n_classes * np.bincount(y))\n",
    "class_weights_map = {cls_idx: total_samples / (num_classes * count) for cls_idx, count in class_counts.items()}\n",
    "class_weights_dict = class_weights_map\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)\n",
    "\n",
    "# Split off a validation set from training data for evaluation and Optuna\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_scaled, y_num, test_size=0.25, stratify=y_num, random_state=42) # Increased validation size for more robust tuning\n",
    "\n",
    "# Optuna objective fn for hyperparam optimization\n",
    "def objective(trial, X_tr, y_tr, X_val, y_val, class_weights_dict):\n",
    "\n",
    "    # Hyperparameters to optimize\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': len(classes),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'class_weight': class_weights_dict,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1 \n",
    "    }\n",
    "\n",
    "    # LGBM models\n",
    "    model = LGBMClassifier(**params)\n",
    "    pruning_callback = LightGBMPruningCallback(trial, 'multi_logloss')\n",
    "\n",
    "    model.fit(X_tr, y_tr,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric='multi_logloss',\n",
    "              callbacks=[pruning_callback],\n",
    "             )\n",
    "\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "    accuracy = balanced_accuracy_score(y_val, val_preds)\n",
    "\n",
    "    return 1.0 - accuracy\n",
    "\n",
    "\n",
    "# Optuna run\n",
    "study_name = 'lgbm-animal-outcome-optimization'\n",
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=10, interval_steps=1)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize',\n",
    "                           study_name=study_name,\n",
    "                           pruner=pruner,\n",
    "                           )\n",
    "\n",
    "\n",
    "n_trials = 50\n",
    "study.optimize(lambda trial: objective(trial, X_tr, y_tr, X_val, y_val, class_weights_dict),\n",
    "               n_trials=n_trials,\n",
    "               )\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nOptuna Finished\")\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Value (Balanced Accuracy): {best_trial.value:.4f}\")\n",
    "print(\"Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\" {key}: {value}\")\n",
    "\n",
    "print(\"\\nTraining Final Model with Best Parameters\")\n",
    "best_params = best_trial.params\n",
    "best_params['objective'] = 'multiclass'\n",
    "best_params['metric'] = 'multi_logloss'\n",
    "best_params['num_class'] = len(classes)\n",
    "best_params['class_weight'] = class_weights_dict\n",
    "best_params['random_state'] = 42\n",
    "best_params['n_jobs'] = -1\n",
    "\n",
    "\n",
    "final_model = LGBMClassifier(**best_params)\n",
    "\n",
    "\n",
    "print(\"Training on full training data\")\n",
    "final_model.fit(X_train_scaled, y_num,\n",
    "               )\n",
    "\n",
    "print(\"\\nValidation Evaluation\")\n",
    "final_val_preds = final_model.predict(X_val)\n",
    "\n",
    "print(\"Balanced Accuracy on val of final model:\", balanced_accuracy_score(y_val, final_val_preds))\n",
    "print(\"Calssification Report:\")\n",
    "print(classification_report(y_val, final_val_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd43533-e613-4935-b2fe-b8182f212050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Predictions\n",
    "print(\"\\nTest set Prediction:\")\n",
    "test_predictions_encoded = final_model.predict(X_test_scaled)\n",
    "\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "test_predictions_labels = pd.Series(test_predictions_encoded).map(idx_to_class)\n",
    "\n",
    "print(\"Sample test predictions:\")\n",
    "print(test_predictions_labels.head())\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({'Id': test['Id'], 'Outcome Type': test_predictions_labels})\n",
    "print(\"\\nSubmission file:\")\n",
    "print(submission.head())\n",
    "submission.to_csv('new_optimized_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4ea8b-6c16-40ba-9b86-3645d95af9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
